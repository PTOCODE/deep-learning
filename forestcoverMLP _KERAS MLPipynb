{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"forestcoverMLP &KERAS MLPipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPWUftghMWdeb5xd4U1x7fl"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"clp9emp_10U5","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from sklearn.datasets import fetch_covtype\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"R9COJe1vH03R","colab_type":"code","colab":{}},"source":["\n","from sklearn.neural_network import MLPClassifier\n","\n","X, y = fetch_covtype(return_X_y=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dEQYPkPPJIDe","colab_type":"code","colab":{}},"source":["X_10 = X[:,:10]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FtFvAWwcH1Cq","colab_type":"code","colab":{}},"source":["# Split the data into 90% training and 10% testing\n","from sklearn.model_selection import train_test_split\n","# The 10% testing data obtained during this split will be take as our entire database.\n","# This is because the original dataset is too big.\n","X10_train, X10_test, y10_train, y10_test = train_test_split(X_10, y, test_size=0.1,\n","stratify=y, random_state=42)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UCNOzphxH1Gr","colab_type":"code","colab":{}},"source":["X = X10_test\n","y = y10_test\n","\n","# Split the data into 80% training and 20% testing\n","from sklearn.model_selection import train_test_split\n","# While splitting, make an unbiased splitting\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n","stratify=y, random_state=42)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zfM-1pnlH1JQ","colab_type":"code","colab":{}},"source":["# Feature scaling using Standardization\n","from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","sc.fit(X_train)\n","\n","X_train_std = sc.transform(X_train)\n","X_test_std = sc.transform(X_test)\n","\n","mlpClassifier = MLPClassifier(solver='lbfgs', alpha=1e-5,\n","hidden_layer_sizes=(50, 25), random_state=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xzqp6VkOH1Wj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"c465ea02-e0b6-4679-b39d-efe9742faab1","executionInfo":{"status":"ok","timestamp":1578855923470,"user_tz":-330,"elapsed":33840,"user":{"displayName":"anamika muralee","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB80Z9b48gDT2hEfH8znqge9gQyNzZisAy6uEP0iw=s64","userId":"01344065240864164178"}}},"source":["\n","mlpClassifier.fit(X_train_std, y_train)\n","\n","\n","score = mlpClassifier.score(X_test_std, y_test)\n","print(score)\n"],"execution_count":13,"outputs":[{"output_type":"stream","text":["0.7513983306083813\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"6nqlb5ttI-7y","colab_type":"text"},"source":["## **USING KERAS MLP**"]},{"cell_type":"code","metadata":{"id":"9AyCf6BpH1FG","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from tensorflow import keras"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"suHsZIdA2M-o","colab_type":"code","colab":{}},"source":["# Setting the random seeds for repeatability\n","tf.set_random_seed(42)\n","np.random.seed(42)\n","\n","# When return_X_y = True, the load function\n","# return data and target instead of Bunch object.\n","X, y = fetch_covtype(return_X_y=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lTs7gO-k2YQK","colab_type":"code","outputId":"0033c6b4-3b10-4f95-d889-a0dc68b1d42e","executionInfo":{"status":"ok","timestamp":1578851641254,"user_tz":-330,"elapsed":3793,"user":{"displayName":"anamika muralee","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB80Z9b48gDT2hEfH8znqge9gQyNzZisAy6uEP0iw=s64","userId":"01344065240864164178"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["# Reduce the number of attributes, consider only first 10 attributes.\n","X_10 = X[:,:10]\n","\n","print(X_10.shape)\n","# (581012, 10)\n","\n","# Split the data into 90% training and 10% testing\n","from sklearn.model_selection import train_test_split\n","\n","# The 10% testing data obtained during this split will be take as our entire database.\n","# This is because the original dataset is too big.\n","X10_train, X10_test, y10_train, y10_test = train_test_split(X_10, y, test_size=0.1,\n","stratify=y, random_state=42)\n","\n","print(X10_test.shape)\n","# (58102, 10)\n","\n","# Handle only the modified 1% dataset. Split that into training and testing.\n","# X and y are updated with the downsized dataset\n","X = X10_test\n","y = y10_test\n","\n","print(set(y))\n","# {1, 2, 3, 4, 5, 6, 7}\n","# The label should start from 0, but by default, the labels are from 1 to 7.\n","# Change them to the range 0 to 6 by subtracting 1 from the labels.\n","y = y-1\n","print(set(y))\n","# {0, 1, 2, 3, 4, 5, 6}\n","\n","# Split the data into 80% training and 20% testing\n","from sklearn.model_selection import train_test_split\n","# While splitting, make an unbiased splitting\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n","stratify=y, random_state=42)\n","\n","# Feature scaling using Standardization\n","from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","# Training the feature scaling parameters\n","sc.fit(X_train)\n","\n","\n","# Applying transformations to both training and testing set\n","X_train_std = sc.transform(X_train)\n","X_test_std = sc.transform(X_test)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(581012, 10)\n","(58102, 10)\n","{1, 2, 3, 4, 5, 6, 7}\n","{0, 1, 2, 3, 4, 5, 6}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GZVBBOUj29gJ","colab_type":"code","outputId":"4ee4cd75-9f47-484c-c44e-fee1cedd6285","executionInfo":{"status":"ok","timestamp":1578851641258,"user_tz":-330,"elapsed":1436,"user":{"displayName":"anamika muralee","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB80Z9b48gDT2hEfH8znqge9gQyNzZisAy6uEP0iw=s64","userId":"01344065240864164178"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["# Create neural network using keras API\n","# Sequential() does linear stacking of layer\n","model_MLP = keras.models.Sequential()\n","# Hidden layer definitions\n","model_MLP.add(keras.layers.Dense(units=25, activation='relu',\n","input_shape= X_train.shape[1:]))\n","# Output layer definitions\n","model_MLP.add(keras.layers.Dense(units=7, activation='softmax'))\n","\n","# Print the summary of network architecture\n","model_MLP.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_2 (Dense)              (None, 25)                275       \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 7)                 182       \n","=================================================================\n","Total params: 457\n","Trainable params: 457\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9qR0tkT63IAE","colab_type":"code","colab":{}},"source":["# Compile the network model with relevant configurations.\n","# loss, optimizer and metrics are three important configurations.\n","model_MLP.compile(loss='sparse_categorical_crossentropy',\n","optimizer='adam', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NIYmhbPy3JH4","colab_type":"code","outputId":"4f9eca58-f25b-4e45-cf98-b0562ec16c3b","executionInfo":{"status":"ok","timestamp":1578851660527,"user_tz":-330,"elapsed":15648,"user":{"displayName":"anamika muralee","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB80Z9b48gDT2hEfH8znqge9gQyNzZisAy6uEP0iw=s64","userId":"01344065240864164178"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["model_MLP.fit(x=X_train_std, y=y_train, validation_split=0.1, epochs=5,batch_size=25)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 41832 samples, validate on 4649 samples\n","Epoch 1/5\n","41832/41832 [==============================] - 3s 69us/sample - loss: 0.9108 - acc: 0.6388 - val_loss: 0.7232 - val_acc: 0.6991\n","Epoch 2/5\n","41832/41832 [==============================] - 3s 69us/sample - loss: 0.7162 - acc: 0.6953 - val_loss: 0.6855 - val_acc: 0.7107\n","Epoch 3/5\n","41832/41832 [==============================] - 3s 68us/sample - loss: 0.6915 - acc: 0.7010 - val_loss: 0.6700 - val_acc: 0.7199\n","Epoch 4/5\n","41832/41832 [==============================] - 3s 70us/sample - loss: 0.6803 - acc: 0.7052 - val_loss: 0.6597 - val_acc: 0.7206\n","Epoch 5/5\n","41832/41832 [==============================] - 3s 68us/sample - loss: 0.6733 - acc: 0.7070 - val_loss: 0.6521 - val_acc: 0.7208\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fe58f332a58>"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"Ko5f87K13M13","colab_type":"code","outputId":"2120e4de-a544-4b2a-d3a0-01ea569c07e9","executionInfo":{"status":"ok","timestamp":1578851718360,"user_tz":-330,"elapsed":1464,"user":{"displayName":"anamika muralee","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB80Z9b48gDT2hEfH8znqge9gQyNzZisAy6uEP0iw=s64","userId":"01344065240864164178"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["test_loss, test_accuracy = model_MLP.evaluate(x=X_test_std, y=y_test)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["11621/11621 [==============================] - 0s 24us/sample - loss: 0.6751 - acc: 0.7092\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"voO4NrIH3S2C","colab_type":"code","outputId":"db40d944-5a50-4503-c955-aab717f9510b","executionInfo":{"status":"ok","timestamp":1578851718363,"user_tz":-330,"elapsed":1151,"user":{"displayName":"anamika muralee","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB80Z9b48gDT2hEfH8znqge9gQyNzZisAy6uEP0iw=s64","userId":"01344065240864164178"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(test_loss, test_accuracy)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0.675096897111683 0.7092333\n"],"name":"stdout"}]}]}