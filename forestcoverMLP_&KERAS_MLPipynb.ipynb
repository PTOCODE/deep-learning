{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "forestcoverMLP &KERAS MLPipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "clp9emp_10U5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import fetch_covtype\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9COJe1vH03R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a413ec8c-7dbd-4ba9-d12a-8b819056a5ef"
      },
      "source": [
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "X, y = fetch_covtype(return_X_y=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://ndownloader.figshare.com/files/5976039\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEQYPkPPJIDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_10 = X[:,:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtFvAWwcH1Cq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the data into 90% training and 10% testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "# The 10% testing data obtained during this split will be take as our entire database.\n",
        "# This is because the original dataset is too big.\n",
        "X10_train, X10_test, y10_train, y10_test = train_test_split(X_10, y, test_size=0.1,\n",
        "stratify=y, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCNOzphxH1Gr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = X10_test\n",
        "y = y10_test\n",
        "\n",
        "# Split the data into 80% training and 20% testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "# While splitting, make an unbiased splitting\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "stratify=y, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfM-1pnlH1JQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature scaling using Standardization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "sc.fit(X_train)\n",
        "\n",
        "X_train_std = sc.transform(X_train)\n",
        "X_test_std = sc.transform(X_test)\n",
        "\n",
        "mlpClassifier = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
        "hidden_layer_sizes=(50, 25), random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzqp6VkOH1Wj",
        "colab_type": "code",
        "outputId": "40d2389d-5298-4c13-f22e-940fdb1e37cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "\n",
        "mlpClassifier.fit(X_train_std, y_train)\n",
        "\n",
        "\n",
        "score = mlpClassifier.score(X_test_std, y_test)\n",
        "print(score)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7513983306083813\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nqlb5ttI-7y",
        "colab_type": "text"
      },
      "source": [
        "## **USING KERAS MLP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AyCf6BpH1FG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "0d4e5477-fdf7-435e-fbfd-e16dd589850b"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suHsZIdA2M-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting the random seeds for repeatability\n",
        "tf.set_random_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# When return_X_y = True, the load function\n",
        "# return data and target instead of Bunch object.\n",
        "X, y = fetch_covtype(return_X_y=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTs7gO-k2YQK",
        "colab_type": "code",
        "outputId": "4bf44df6-b4d0-4d1d-e01f-74a6e06634ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Reduce the number of attributes, consider only first 10 attributes.\n",
        "X_10 = X[:,:10]\n",
        "\n",
        "print(X_10.shape)\n",
        "# (581012, 10)\n",
        "\n",
        "# Split the data into 90% training and 10% testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# The 10% testing data obtained during this split will be take as our entire database.\n",
        "# This is because the original dataset is too big.\n",
        "X10_train, X10_test, y10_train, y10_test = train_test_split(X_10, y, test_size=0.1,\n",
        "stratify=y, random_state=42)\n",
        "\n",
        "print(X10_test.shape)\n",
        "# (58102, 10)\n",
        "\n",
        "# Handle only the modified 1% dataset. Split that into training and testing.\n",
        "# X and y are updated with the downsized dataset\n",
        "X = X10_test\n",
        "y = y10_test\n",
        "\n",
        "print(set(y))\n",
        "# {1, 2, 3, 4, 5, 6, 7}\n",
        "# The label should start from 0, but by default, the labels are from 1 to 7.\n",
        "# Change them to the range 0 to 6 by subtracting 1 from the labels.\n",
        "y = y-1\n",
        "print(set(y))\n",
        "# {0, 1, 2, 3, 4, 5, 6}\n",
        "\n",
        "# Split the data into 80% training and 20% testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "# While splitting, make an unbiased splitting\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "stratify=y, random_state=42)\n",
        "\n",
        "# Feature scaling using Standardization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "# Training the feature scaling parameters\n",
        "sc.fit(X_train)\n",
        "\n",
        "\n",
        "# Applying transformations to both training and testing set\n",
        "X_train_std = sc.transform(X_train)\n",
        "X_test_std = sc.transform(X_test)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(581012, 10)\n",
            "(58102, 10)\n",
            "{1, 2, 3, 4, 5, 6, 7}\n",
            "{0, 1, 2, 3, 4, 5, 6}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZVBBOUj29gJ",
        "colab_type": "code",
        "outputId": "77f66791-18ce-4042-cbf1-940a7bffe61a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "# Create neural network using keras API\n",
        "# Sequential() does linear stacking of layer\n",
        "model_MLP = keras.models.Sequential()\n",
        "# Hidden layer definitions\n",
        "model_MLP.add(keras.layers.Dense(units=25, activation='relu',\n",
        "input_shape= X_train.shape[1:]))\n",
        "# Output layer definitions\n",
        "model_MLP.add(keras.layers.Dense(units=10, activation='softmax'))\n",
        "\n",
        "# Print the summary of network architecture\n",
        "model_MLP.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 25)                275       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                260       \n",
            "=================================================================\n",
            "Total params: 535\n",
            "Trainable params: 535\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qR0tkT63IAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the network model with relevant configurations.\n",
        "# loss, optimizer and metrics are three important configurations.\n",
        "model_MLP.compile(loss='sparse_categorical_crossentropy',\n",
        "optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIYmhbPy3JH4",
        "colab_type": "code",
        "outputId": "1334433e-c92d-4498-b817-8e7a1e1d48ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "model_MLP.fit(x=X_train_std, y=y_train, validation_split=0.1, epochs=5,batch_size=25)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 41832 samples, validate on 4649 samples\n",
            "Epoch 1/5\n",
            "41832/41832 [==============================] - 3s 64us/sample - loss: 0.9139 - acc: 0.6449 - val_loss: 0.7158 - val_acc: 0.7032\n",
            "Epoch 2/5\n",
            "41832/41832 [==============================] - 3s 60us/sample - loss: 0.7136 - acc: 0.6971 - val_loss: 0.6816 - val_acc: 0.7094\n",
            "Epoch 3/5\n",
            "41832/41832 [==============================] - 2s 59us/sample - loss: 0.6902 - acc: 0.7025 - val_loss: 0.6673 - val_acc: 0.7163\n",
            "Epoch 4/5\n",
            "41832/41832 [==============================] - 2s 60us/sample - loss: 0.6794 - acc: 0.7065 - val_loss: 0.6581 - val_acc: 0.7204\n",
            "Epoch 5/5\n",
            "41832/41832 [==============================] - 2s 59us/sample - loss: 0.6732 - acc: 0.7089 - val_loss: 0.6522 - val_acc: 0.7202\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff70a718c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko5f87K13M13",
        "colab_type": "code",
        "outputId": "8b927c7a-0911-46a9-c6c4-cd2707cd2cb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_loss, test_accuracy = model_MLP.evaluate(x=X_test_std, y=y_test)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11621/11621 [==============================] - 0s 20us/sample - loss: 0.6766 - acc: 0.7127\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voO4NrIH3S2C",
        "colab_type": "code",
        "outputId": "0a5416a8-db90-493b-be01-262eeb987c78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(test_loss, test_accuracy)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6765611668880851 0.71267533\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}