{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Biomechanical_features_of_orthopedic_patientsMLP&USINGKERASMLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxENKp_eWftd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQ4J5rRIWsZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOAXUT-fBYpv",
        "colab_type": "code",
        "outputId": "c38eef86-8037-4b91-82b2-afcd58a2e5f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMK_iogyWz57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset=pd.read_csv('/content/drive/My Drive/datasets/column_2C_weka.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxnJLUv8W5Kl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=dataset.iloc[:,:-1].values\n",
        "y=dataset.iloc[:,6].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25MYGzOdW8fI",
        "colab_type": "code",
        "outputId": "ce46b6e9-4475-4bf5-eb94-d48b060daff9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print (dataset.isnull().values.any())"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymaIrnACXDqL",
        "colab_type": "text"
      },
      "source": [
        "CATEGORICAL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNnAyw4iW_rq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing  import LabelEncoder,OneHotEncoder\n",
        "labelencoder_y=LabelEncoder()\n",
        "y=labelencoder_y.fit_transform(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TP9Rmf7XKNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# for unbiased splitting\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y,\n",
        "random_state=42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZ9x3UpUXequ",
        "colab_type": "text"
      },
      "source": [
        "MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSjZeiOwXVla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlpClassifier = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
        "hidden_layer_sizes=(25, 10), random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5IK6yb5XgEk",
        "colab_type": "code",
        "outputId": "b81855e2-a5f7-4cd6-f26c-b732c8b736f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "mlpClassifier.fit(X_train, y_train)\n",
        "\n",
        "score = mlpClassifier.score(X_test, y_test)\n",
        "\n",
        "print(score)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8709677419354839\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoDaaHrxB3JK",
        "colab_type": "text"
      },
      "source": [
        "USING  KERAS MLP\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xR440RdXjHX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing both TensorFlow and its high level API - Keras.\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "# Setting the random seeds for repeatability\n",
        "tf.set_random_seed(42)\n",
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mngoGqHB_J0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the data into 80% training and 20% testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "random_state=42)\n",
        "# Feature scaling using Standardization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "# Training the feature scaling parameters\n",
        "sc.fit(X_train)\n",
        "# Applying transformations to both training and testing set\n",
        "X_train_std = sc.transform(X_train)\n",
        "X_test_std = sc.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8UKMJsACBT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_MLP = keras.models.Sequential()\n",
        "# Hidden layer definitions\n",
        "model_MLP.add(keras.layers.Dense(units=5, activation='relu',\n",
        "input_shape= X_train.shape[1:]))\n",
        "# Output layer definitions\n",
        "model_MLP.add(keras.layers.Dense(units=1, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AB9L6yjwCEH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_MLP.compile(loss='binary_crossentropy',\n",
        "optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBNmL6DECGt9",
        "colab_type": "code",
        "outputId": "b5843d3d-2853-4396-d759-1574c82a94aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_MLP.fit(x=X_train_std, y=y_train, validation_split=0.1,\n",
        "epochs=50, batch_size=16)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 223 samples, validate on 25 samples\n",
            "Epoch 1/50\n",
            "223/223 [==============================] - 0s 631us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 2/50\n",
            "223/223 [==============================] - 0s 219us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 3/50\n",
            "223/223 [==============================] - 0s 151us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 4/50\n",
            "223/223 [==============================] - 0s 155us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 5/50\n",
            "223/223 [==============================] - 0s 154us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 6/50\n",
            "223/223 [==============================] - 0s 211us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 7/50\n",
            "223/223 [==============================] - 0s 160us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 8/50\n",
            "223/223 [==============================] - 0s 153us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 9/50\n",
            "223/223 [==============================] - 0s 153us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 10/50\n",
            "223/223 [==============================] - 0s 199us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 11/50\n",
            "223/223 [==============================] - 0s 152us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 12/50\n",
            "223/223 [==============================] - 0s 177us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 13/50\n",
            "223/223 [==============================] - 0s 142us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 14/50\n",
            "223/223 [==============================] - 0s 151us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 15/50\n",
            "223/223 [==============================] - 0s 183us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 16/50\n",
            "223/223 [==============================] - 0s 197us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 17/50\n",
            "223/223 [==============================] - 0s 171us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 18/50\n",
            "223/223 [==============================] - 0s 174us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 19/50\n",
            "223/223 [==============================] - 0s 158us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 20/50\n",
            "223/223 [==============================] - 0s 150us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 21/50\n",
            "223/223 [==============================] - 0s 168us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 22/50\n",
            "223/223 [==============================] - 0s 153us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 23/50\n",
            "223/223 [==============================] - 0s 160us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 24/50\n",
            "223/223 [==============================] - 0s 163us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 25/50\n",
            "223/223 [==============================] - 0s 151us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 26/50\n",
            "223/223 [==============================] - 0s 151us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 27/50\n",
            "223/223 [==============================] - 0s 177us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 28/50\n",
            "223/223 [==============================] - 0s 189us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 29/50\n",
            "223/223 [==============================] - 0s 180us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 30/50\n",
            "223/223 [==============================] - 0s 145us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 31/50\n",
            "223/223 [==============================] - 0s 149us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 32/50\n",
            "223/223 [==============================] - 0s 160us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 33/50\n",
            "223/223 [==============================] - 0s 173us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 34/50\n",
            "223/223 [==============================] - 0s 195us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 35/50\n",
            "223/223 [==============================] - 0s 187us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 36/50\n",
            "223/223 [==============================] - 0s 165us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 37/50\n",
            "223/223 [==============================] - 0s 153us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 38/50\n",
            "223/223 [==============================] - 0s 145us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 39/50\n",
            "223/223 [==============================] - 0s 166us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 40/50\n",
            "223/223 [==============================] - 0s 195us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 41/50\n",
            "223/223 [==============================] - 0s 154us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 42/50\n",
            "223/223 [==============================] - 0s 153us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 43/50\n",
            "223/223 [==============================] - 0s 160us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 44/50\n",
            "223/223 [==============================] - 0s 170us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 45/50\n",
            "223/223 [==============================] - 0s 159us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 46/50\n",
            "223/223 [==============================] - 0s 155us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 47/50\n",
            "223/223 [==============================] - 0s 157us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 48/50\n",
            "223/223 [==============================] - 0s 156us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 49/50\n",
            "223/223 [==============================] - 0s 151us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n",
            "Epoch 50/50\n",
            "223/223 [==============================] - 0s 140us/sample - loss: 10.2451 - acc: 0.3318 - val_loss: 10.3695 - val_acc: 0.3200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3e901580f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyvHBX7pCI7n",
        "colab_type": "code",
        "outputId": "cf623fc6-18e9-4a2f-f92b-2e5d2f0847d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "test_loss, test_accuracy = model_MLP.evaluate(x=X_test_std, y=y_test)\n",
        "print(test_loss, test_accuracy)\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "62/62 [==============================] - 0s 97us/sample - loss: 10.8220 - acc: 0.2903\n",
            "10.822040004114951 0.29032257\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qV6W93vBulqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}